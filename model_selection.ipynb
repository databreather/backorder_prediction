{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bed4d058",
   "metadata": {},
   "source": [
    "# Backorder Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe78475",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0335911e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold,train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, make_scorer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a13d9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./dataset/Kaggle_Training_Dataset_v2.csv\", low_memory=False)\n",
    "test_df = pd.read_csv(\"./dataset/Kaggle_Test_Dataset_v2.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60755d51",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f309f896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(df):\n",
    "    \n",
    "    df.drop('sku', axis=1, inplace=True)\n",
    "    df.dropna(how='all', inplace=True)\n",
    "\n",
    "    numerical_cols = [col for col in df.columns if df[col].dtype != 'object']\n",
    "    categorical_cols = [col for col in df.columns if col not in numerical_cols]\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if col in 'lead_time':\n",
    "            df[col] = SimpleImputer(missing_values=np.nan, strategy='median').fit_transform(df[col].values.reshape(-1, 1))\n",
    "        if col in ['perf_6_month_avg', 'perf_12_month_avg']:\n",
    "            df[col] = SimpleImputer(missing_values=-99, strategy='median').fit_transform(df[col].values.reshape(-1, 1))\n",
    "        if col in categorical_cols:\n",
    "            df[col] = (df[col] == 'Yes').astype(int)\n",
    "    \n",
    "    # Normalize attributes related to quantities\n",
    "    norm_cols = [col for col in numerical_cols if col not in ['lead_time', 'perf_6_month_avg', 'perf_12_month_avg']]\n",
    "    \n",
    "    df[norm_cols] = normalize(df[norm_cols], axis=1)\n",
    "    \n",
    "    #df['lead_time'] = df['lead_time']/df['lead_time'].max().astype(np.float64)\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe406ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = process(train_df.append(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990f8b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6cd6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b611b6",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5870547",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(X, y, title=''):\n",
    "    X_std = StandardScaler().fit_transform(X)\n",
    "    dec = PCA(n_components=2)\n",
    "    X_reduced = dec.fit_transform(X_std)\n",
    "    \n",
    "    f, ax = plt.subplots(figsize=(6,6))\n",
    "    ax.scatter(X_reduced[y==0,0], X_reduced[y==0,1], alpha=0.5, \n",
    "               facecolors='none', edgecolors='cornflowerblue', label=\"Negative\")\n",
    "    ax.scatter(X_reduced[y==1,0], X_reduced[y==1,1], c='darkorange', marker='*', \n",
    "               label='Positive')\n",
    "    plt.title(\"Explained Variance ratio: %.2f%%\" % (100*dec.explained_variance_ratio_.sum()))\n",
    "    ax.legend(loc='lower left')\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.set_xlabel('PC1')\n",
    "    ax.set_ylabel('PC2')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42c5ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = data.sample(6000, random_state=56)\n",
    "X_sample = sample.iloc[:, :-1].values\n",
    "y_sample = sample.iloc[:, -1].values\n",
    "plot(X_sample, y_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf91356",
   "metadata": {},
   "source": [
    "## Split into train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cf0fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046d8b9d",
   "metadata": {},
   "source": [
    "## Standardize training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233eaa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "X_std = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944f0d97",
   "metadata": {},
   "source": [
    "## Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d12e913",
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = LogisticRegression()\n",
    "lg.fit(X_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bc0924",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = lg.predict(X_test)\n",
    "accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6d01a8",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcf028f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 5\n",
    "scorer = make_scorer(average_precision_score, needs_threshold=True, average='micro')\n",
    "min_samples_leaf=5\n",
    "n_estimators=10\n",
    "criterion='entropy'\n",
    "max_depth=np.arange(3,45,5)\n",
    "max_depth=[3,4,5,7,10,15,20,30,50]\n",
    "n_folds=5\n",
    "estimators = [\n",
    "#     (\"lgst\", LogisticRegression(), {'C': np.logspace(0, 3, 4), 'penalty': ['l1', 'l2'], 'solver': ['liblinear']}),\n",
    "    ('cart', DecisionTreeClassifier(min_samples_leaf=5, criterion='entropy'), {'max_depth': max_depth, 'criterion': ['gini', 'entropy']}),\n",
    "    ('rus', Pipeline([('res', RandomUnderSampler()), ('tree', DecisionTreeClassifier(min_samples_leaf=5, criterion='entropy'))]), {'tree__max_depth': max_depth}),\n",
    "    ('smt', Pipeline([('res', SMOTE()), ('tree', DecisionTreeClassifier(min_samples_leaf=5, criterion='entropy'))]), {'tree__max_depth': max_depth}),\n",
    "    ('rf', RandomForestClassifier(n_estimators=10, min_samples_leaf=5, criterion='entropy'), {'max_depth': max_depth}),\n",
    "    ('gb', GradientBoostingClassifier(n_estimators=10, min_samples_leaf=5), {'max_depth': max_depth})\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de69a06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for est_name, est, params in estimators:\n",
    "    matrix = []\n",
    "    t0 = time.time()\n",
    "    \n",
    "    for run in range(n_runs):\n",
    "        X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, stratify=y, test_size=0.15, random_state=run)\n",
    "#         scaler1 = StandardScaler().fit(X_train1)\n",
    "#         X_std1 = scaler1.transform(X_train1)\n",
    "        kf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=int(run*9))\n",
    "        gs = GridSearchCV(est, params, cv=kf, scoring=scorer, verbose=0, n_jobs=1)\n",
    "        \n",
    "        t1 = time.time()\n",
    "        gs.fit(X_train1, y_train1)\n",
    "\n",
    "        y_prob0 = gs.best_estimator_.predict_proba(X_train1)[:, 1]\n",
    "        y_prob = gs.best_estimator_.predict_proba(X_test1)[:, 1]\n",
    "        \n",
    "        roc = roc_auc_score(y_test1, y_prob)\n",
    "        pr = average_precision_score(y_test1, y_prob)\n",
    "        \n",
    "        run_time = time.time() - t1\n",
    "        avg_time = run_time/gs.n_splits_\n",
    "        \n",
    "        print (\"%i\\t%s\\t%.4f\\t%.4f\\t%.4f\\t%.2f\\t%s\" % (run, est_name, \n",
    "            gs.best_score_, roc, pr, avg_time, gs.best_params_))\n",
    "\n",
    "        \n",
    "        # get importance\n",
    "        imp = []\n",
    "        model = gs.best_estimator_\n",
    "    \n",
    "        if est_name in ['rus','smt']:\n",
    "            imp = model.named_steps['tree'].feature_importances_\n",
    "        elif est_name == 'lgst':\n",
    "            imp = model.coef_.ravel()\n",
    "        else:\n",
    "            imp = model.feature_importances_\n",
    "        \n",
    "        matrix.append(\n",
    "        {   'run'           : run,\n",
    "            'estimator'     : est_name,         \n",
    "            'roc'           : roc,\n",
    "            'pr'            : pr,\n",
    "            'best_params'   : gs.best_params_, \n",
    "            'avg_time'      : avg_time,\n",
    "            'importance'    : imp,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2be7a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
